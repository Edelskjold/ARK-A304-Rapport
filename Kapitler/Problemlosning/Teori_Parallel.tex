\subsection{Parallel og asynkron programmering}
\label{subsec:pprogrammering}
Parallel/asynkron programmering og multithreading er meget omfattende og indviklede emner. Derfor vil dette afsnit kun indeholde en grundlæggende forklaring af anvendte koncepter inden for emnet, da afsnittet ellers ville blive uhensigtsmæssigt stort i forhold til hvor stor en rolle, emnet spiller i løsningen.\\

Parellel og asynkron programmering er reelt to forskellige ting, men de hænger ofte tæt sammen - og anvendes de i tandem, er de langt mere effektive. Denne fælles beskrivelse skyldes også at det i .Net-regi fungerer ved at man anvender en abstraktion; .Net implementerer en klasse kaldet Task, som repræsenterer en asynkron operation - dvs. en operation der ikke vødvendigvis eksekveres med det samme. Man taler derfor om en "Future" - altså en lovning på at et resultat. Fordelen ved denne abstraktion er, at man har ikke eksplicit specificeret, hvordan operationen skal udføres, og derfor kan denne optimeres. Dette betyder dog også, at programmøren ikke er herre over hvorvidt operationen bliver udført asynkront eller parallelt.\\

Parallel programmering har flere forskellige formål, og kan ligeledes opnåes på flere forskellige måder, afhængigt hvilken type opgave man ønsker at parallellisere\cite{accuthreading}. I forhold til løsningen bliver parallellisering hovedsageligt udnyttet til at undgå at blokere den primære tråd - dvs. den tråd der sørger for at drive programmets UI. Ved at undgå at blokere denne tråd, sørger man for, at UI'et fortsætter med at være responsivt, selv mens programmet udfører en opgave der tager længere tid. Hvis det er en I/O-operation\footnote{Input/Output operation}, kan denne håndteres ved at registere en callback-funktion \cite{callback} eller vha. et hardware-interrupt\cite{hwinterrupt1}\cite{hwinterrupt2}. De to førstnævnte metoder til at implementere non-blocking I/O \cite{accuthreading}, eller abstraktionen, kan sørge for at oprette en separat tråd til at foretage disse udregninger. Den kan også udsætte udførslen til en gang ude i fremtiden, hvor den primære tråd er inaktiv - derfor navnet "Future"\mbox{}. Programmøren ved ikke hvornår funktionen returnerer - kun at den gør på et tidspunkt. Den samme fleksibilitet er dog ikke mulig, hvis der skal foretages udregninger. I så fald er det nødvendigt at benytte en separat tråd eller vente på ledige ressourcer på hovedtråden.

\subsubsection*{Parallel programming}
Specifikt i forhold til parallelitet skelner man fra et udviklerperspektiv mellem to forskellige former; data parallelitet og "opgave"\mbox{}-parallelitet \cite{parallelism1}\cite{parallelism2}.\\
For at forklare forskellen er det nødvendigt at forklare hvad der forståes ved "opgave" eller task. En "opgave" er et sæt af operationer, som ved udførsel giver et bestemt resultat. Forskellen beror på hvordan paralleliteten opnåes; for data parallelitet udfører man den samme operation, på forskellige elementer, i et datasæt på samme tid, hvor det for "opgave" parallelitet handler om at en opgave splittes op i uafhængige underopgaver, hvorefter disse udføres simultant af flere tråde. Kort sagt; data parallelitet handler om parallel udførsel af samme task på flere elementer, hvor "opgave" parallelitet handler om parallel udførsel af flere underdele af en task.